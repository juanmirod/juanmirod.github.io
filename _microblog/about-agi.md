---
layout: micro
date: 16/05/2023
---

El otro día en una conversación con alguien que lleva en ML varias décadas me confirmó una intuición que yo tenía con chatGPT y GPT4: estos modelos "piensan" con el output, es decir su memoria de trabajo es el output que van generando y que va guiando el resto del output...
Translate Tweet
10:00 PM · May 14, 2023











Una vez el output termina el modelo es como si se apagara, no existe entre pregunta y pregunta y no puede recordar nada de una petición a otra (el contexto de la conversación es una ilusión que queda clara sí usas el API...) Por tanto
Juanmi
@juanmirod
·
May 14
Qué pasaría si consiguiéramos que el modelo pensara todo el rato? Que tuviera una memoria permanente que le permitiera interrogarse a si mismo y mantener un modelo del mundo y de él? Esto es lo que creo que asusta a algunos y lo que otros quieren conseguir con autogpt o babygpt
Juanmi
@juanmirod
·
May 14
Parece obvio que el enfoque de conseguirlo con la API es erróneo y que el LLM será solo una parte de este sistema integrado. Es hacia donde se está trabajando ahora mismo y por eso lo de llamarlos "modelos fundacionales"...
Juanmi
@juanmirod
·
May 14
Si conseguimos, conectar, de una forma más integral que a través de prompts, una memoria permanente, una forma de modelar el mundo y de modificar esos modelos, los LLMs... Eso sería enorme, pero entraríamos de cabeza en los problemas de inner alignment.
Juanmi
@juanmirod
·
May 14
Lo que creo es que Hinton dejó Google por qué sabe de buena tinta que hay gente muy lista trabajando en esto y hasta puede que lo haya visto muy cerca. Al menos eso es lo que entiendo yo de sus entrevistas y del estado del arte actual...
