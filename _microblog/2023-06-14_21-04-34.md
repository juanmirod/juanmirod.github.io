---
published: true
layout: micro
date: 2023-06-14
---

Escuchando a Timnit Gebru o Emily M. Bender en "Tech won't save us" me da la sensación de que niegan la mayor 
en cuanto al tema de la AGI simplemente porque no están de acuerdo políticamente o con los objetivos de OpenAI
o de Elon Musk. O simplemente por tener una visión humanista. Expresiones como "no he leído nada de ChatGPT porque
no tengo tiempo de leer texto sintético" o "estos modelos no son inteligentes porque no hay una intencionalidad humana
de comunicación" les hacen perder la razón desde mi punto de vista.

Estoy de acuerdo en que tenemos que ver estas herramientas como tales y no encumbrarlas al nivel de dioses o tan siquiera
equipararlas con las personas mientras no tengan ciertos atributos (agencia, memoria, persistencia...) Pero no estoy
nada de acuerdo en que el lenguaje sólo tenga sentido como forma de comunicación humana y que nuestra inteligencia sea
la única a modelar. 

Tengo que leer más de ellas. Weapons of math destruction (las dos lo citaron y creo que es el libro más citado por esta
corriente de pensamiento) me encantó y creo que es muy educativo para cualquiera que trabaje
con datos. Los problemas que señala son reales y actuales y necesitan solución, pero descartar totalmente las posibilidades
de los LLMs me parece corto de miras...
