---
published: true
title: Mi experiencia en NLP
description: Cuento c칩mo me interes칠 en NLP y en LLMs desarrollando un chabot
image: /public/img/med-badr-chemmaoui-ZSPBhokqDMc-unsplash.jpg
layout: post
audio: experiencia-nlp_nova.mp3
tags: [opini칩n, Inteligencia Artificial, NLP, audio]
---

<figure>
    <img src="/public/img/med-badr-chemmaoui-ZSPBhokqDMc-unsplash.jpg"
         alt="An image of a block with some wireframes and a pen">
    <figcaption>Photo by <a href="https://unsplash.com/@medbadrc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Med Badr  Chemmaoui</a> on <a href="https://unsplash.com/photos/ZSPBhokqDMc?utm_source=unsplash&utm_medium=referral&utm_content=creditCopyText">Unsplash</a>
</figcaption>
</figure>
  
Hace tiempo que quiero contar esta historia bien contada y creo que es ahora o nunca. Mi experiencia personal con el NLP tiene varios a침os y creo que explica por qu칠 me ha interesado tanto ChatGPT y por qu칠 creo que esta tecnolog칤a tiene tanto potencial. Pero empecemos por el principio:

> Warning! tengo muy mala memoria, cualquier parecido con la realidad ser치 casi accidental, voy a tratar de resumir varios a침os de trabajo a grosomodo en un post por dejar constancia de mi viaje y por ordenar un poco mis pensamientos, pero como todo este blog, es p칰blico por si a alguien m치s le puede servir.

Alrededor de 2017 empec칠 a trabajar en una empresa en un proyecto de NLP casi por casualidad. Yo hab칤a trabajado hasta ese momento fundamentalmente con la web, haciendo aplicaciones, juegos, peque침as webs corporativas, campa침as de publicidad... nada demasiado sofisticado y eso si casi siempre trabajando como 칰nico desarrollador, lo que llaman ahora un "full stack": yo hac칤a el backend, la base de datos, las migraciones, la administraci칩n de sistemas y el frontend. S칩lo me faltaba hacer los dise침os.

A esta empresa y su forma de trabajar le encaj칩 bastante, porque aunque hab칤a varios desarrolladores, cada uno trabaj치bamos de forma independiente en nuestro proyecto, en nuestra oficina personal. En este caso la infra no hab칤a que gestionarla (oh yeah) pero todo lo dem치s s칤. Incluso, en mi caso, la planificaci칩n del proyecto y la gran mayor칤a de las decisiones ca칤an de mi parte. Digamos que era una especie de investigaci칩n y desarrollo muy aplicado, sin ser yo investigador y sin publicar nada, pero s칤 que un royo bastante libre de "tienes que hacer esto y t칰 te apa침as el c칩mo lo consigues"

La tarea por aquel entonces ya empezaba a estar de moda pero aun todo lo que hab칤a era muy tosco: programar un asistente virtual. Google ten칤a Home, Amazon Alexa, iPhone a Siri, no es que fueran super 칰tiles, pero ah칤 estaban. Y muchas empresas se embarcaron en la tarea de tener su propio chatbot, aunque no ten칤an muy claro c칩mo se hac칤a eso.

![A 3d render of a virtual robot on top of a phone - generated with Ideogram](/public/img/chatbot.jpeg)

En mi caso, al tener mucha libertad y tiempo para desarrollar (no hab칤a pr치cticamente reuniones ni necesidad de coordinaci칩n) me empec칠 a meter en el mundo NLP y en c칩mo programar un Chatbot.

Empec칠 por atacarlo por donde sab칤a. En aquel entonces ya se empezaba a hablar de los modelos de lenguaje, pero yo no ten칤a ni idea de ML ni recursos para aprender o contratar a nadie, as칤 que por el momento descart칠 ese camino y fui investigando sobre lenguajes, sistemas expertos, NLP cl치sico...

As칤 llegu칠 a [ChatScript](https://github.com/ChatScript/ChatScript), que es un lenguaje a medida dise침ado y creado por [Bruce Wilcox](https://en.wikipedia.org/wiki/Bruce_Wilcox), para programar chatbots. La verdad es que me pareci칩 lo mejor que hab칤a en la 칠poca. En ese momento la mayor칤a de la gente usaba o bien [AIML](https://en.wikipedia.org/wiki/Artificial_Intelligence_Markup_Language), un lenguaje anterior parecido pero basado en XML que era un horror (pero con el que estaba programado el chatbot m치s famoso y exitoso hasta el momento y que sigue en activo: [Mitsuku](https://en.wikipedia.org/wiki/Kuki_AI)), ChatScript (con el que Bruce Wilcox hab칤a ganado varias veces el premio Loebner y creo que hab칤a desarrollado trabajando en Telltale games como motor conversacional de sus aventuras) o python+NLTLK+spacy, que en el momento permit칤a tokenizar el texto de entrada y luego crear un mont칩n de reglas por palabras, por frases, por entity detection etc, que al final se parec칤an bastante a ChatScript, pero eran bastante m치s feas de escribir y de entender y probar. Adem치s ChatScript era infinitamente m치s r치pido (daba la respuesta en milisegundos y era un servidor independiente muy f치cil de hacer deploy y con una API muy simple) y ya tra칤a un mont칩n de reglas de uso general y algunos ejemplos de agentes... As칤 que me decid칤 por ChatScript.

Encima de ChatScript pude hacer bastantes cositas. Llegu칠 a hacer un interface gr치fico que permit칤a crear chatbots sin que el usuario tuviera ni idea de programar, que luego compilaba a ChatScript, generalizando los ejemplos del usuario y que permit칤a probar y debugar tus conversaciones. Es decir era un [Proyectional editor](https://www.martinfowler.com/bliki/ProjectionalEditing.html) para una DSL que hab칤a constru칤do encima de ChatScript. En resumen: me lo pas칠 bomba. Pero si has programado alg칰n sistema parecido ya sabr치s c칩mo acaba la cosa...

Yo hab칤a estado leyendo mucho, sobre [Wilcox y ChatScript](https://github.com/ChatScript/ChatScript/tree/master/PAPERS), el premio Loebner y chatbots en general. [Sobre Watson, c칩mo lo desarrollaron y su arquitectura](/public/papers/ferrucci2012.pdf). Sobre [Yedalog](/public/papers/yedalog.pdf), [Datalog](https://en.wikipedia.org/wiki/Datalog), sobre [DSLs](https://martinfowler.com/dsl.html), sobre modelos de lenguaje, ML, NLP... Hab칤a le칤do un poco a [Norvig](https://colab.research.google.com/github/norvig/pytudes/blob/main/ipynb/How%20to%20Do%20Things%20with%20Words.ipynb), [lo suficiente como para saber que s칩lo con reglas no iba a conseguir mi objetivo, por muy r치pido e ingenioso que fuera ChatScript](http://norvig.com/chomsky.html).

(Tangencialmente, tanto Wilcox como Norvig hab칤an trabajado en LISP, y adem치s estaba en pleno auge el furor por la programaci칩n funcional en JavaScript, as칤 que tambi칠n me interes칠 bastante en LISP y en Clojure, pero eso es otra historia, que contar칠 en otro momento ;))

De leer todo esto hab칤a sacado muchas ideas y hab칤a a침adido muchas heur칤sticas a mi chatbot. Hab칤a a침adido cientos de tests end to end autom치ticos para saber que al a침adir nueva funcionalidad, el chatbot no dejaba de responder bien a las acciones que ya conoc칤a... A침ad칤 un peque침o motor l칩gico que permit칤a "ense침arle cosas", es decir guardar hechos y relaciones mediante lenguaje m치s o menos natural... Todo con la intenci칩n de construir un sistema lo bastante flexible como para poder seguir a침adi칠ndole "servicios" o piezas que lo hicieran m치s inteligente, como en Watson.

Desde el principio el chatbot pod칤a recibir de input y responder en cualquier idioma gracias a la API de traducci칩n de Google, que hac칤a la conversi칩n y de algunas reglas para detectar, almacenar el idioma y hacer la conversi칩n de la salida desde ese momento para ese usuario.

Yo estaba bastante contento con mi peque침o sistema experto multirepo que era capaz de responder a un pu침ado de preguntas, hacer bromas y tener peque침as conversaciones, siempre que preguntaras la pregunta adecuada...

**Pero tratar de programar un chatbot o un asistente gen칠rico, que responda airosamente a texto libre, escribiendo reglas a mano, es una tarea imposible.** Por mucho que generalicen tus reglas, mucho entity detection, bases de datos con ciudades, nombres, animales y dem치s que tengas, por m치s que tokenices la frase y que elimines las palabras superfluas como los art칤culos, por m치s que uses regex en tus reglas, siempre llegar치 el usuario, intentar치 hablar con tu programa y tu programa fracasar치 estrepitosamente en entenderlo, si no a la primera, a la segunda frase.

Era bastante frustrante tener miles de tests unitarios, cientos de tests autom치ticos de conversaciones e2e en varias categor칤as, desde hablar del usuario, dar el tiempo, la hora, preguntas de c치lculos, bromas, ejecutar comandos, memorizar cosas, recordar cosas, poner contadores... y que nada m치s intentar probarlo alguien, fallara en entenderlo y respondiera con un "lo siento, no te entiendo" o algunas de las decenas de frases que tiene ChatScript para intentar salir del paso en ese caso.

Pero entonces en la empresa me hicieron un regalo: Un compa침ero!! Hab칤a otro programador, esta vez alguien especializado en ML, que estaba intentando el mismo problema usando todo ese royo de Python y Spacy, con el mismo o menos 칠xito que yo, as칤 que nos pusimos los dos a intentar aunar fuerzas.

Yo ya ten칤a el servidor funcionando y adem치s como hab칤a a침adido todos esos m칩dulos independientes y hab칤a ido desacoplando todo, pod칤a incorporar otro servidor, en este caso de ML, que respondiera a todo aquello que a mi chatbot se le escapaba. Al principio fue solo eso, luego fuimos a침adiendo pesos, y si el ML estaba muy seguro de la respuesta, respond칤a el ML, si no, el chatbot, si el chatbot no ten칤a respuesta, respond칤amos algo gen칠rico.

Para poder encajar todo esto, ayud칠 un poco con el servidor de Python del sistema de ML, y esto me permiti칩 acercarme un poco m치s a ese mundo. En el lado de Python usamos flask para el servidor y RASA para el chatbot. RASA ten칤a apenas unos meses y estaba muy verde (de hecho no exist칤a o era poco m치s que una idea cuando yo empec칠 a investigar sobre el tema), us치bamos spacy para tokenizaci칩n y otras tareas cl치sicas de NLP pero por debajo de RASA lo customizamos un poco y el otro programador ten칤a tus propios modelos para detecci칩n de entidades y generaci칩n de lenguaje.

Todo esto fue antes de GPT2, y trat치bamos de seguir los 칰ltimos papers que iban saliendo sobre el tema. Yo me hab칤a familiarizado con los papers acad칠micos porque sobre todo este tema apenas encontrabas informaci칩n y cursos m치s asequibles en la web[^1], y aunque pasaba de largo de las matem치ticas, pod칤a leer m치s o menos los papers que 칤bamos viendo que pod칤an ser interesantes.

Ni que decir tiene que nuestro chatbot segu칤a siendo bastante patata, pero tenia un mont칩n de funcionalidades si sab칤as usarlo. Este era el problema siempre antes de GPT3.5, simplemente no exist칤a nada que entendiera la pregunta y diera una respuesta coherente. Ahora mismo nos quejamos de que la IA se _"inventa"_ cosas, pero el salto es abismal, **en 2019 el estado del arte era**:

1. **Tokenizar** y limpiar la entrada
2. **Detecci칩n de entidades** con diccionarios en el lado cl치sico o con un NER en ML.
3. **Clasificaci칩n de la intenci칩n** de la frase:
   - En el lado cl치sico esto eran cientos o miles de reglas y regex para tratar de hacer matchear la frase con un patr칩n conocido.
   - En ML pod칤as entrenar un clasificador con las intenciones que tuvieras y el clsaificador te daba una intenci칩n o varias con un margen de confianza.
4. Con la intenci칩n, si tienes algo con confianza alta, y tienes las entidades (variables como Paris, Juan o concierto) **puedes intentar responder**. Si no, tienes un backup tipo [ELISA](https://en.wikipedia.org/wiki/ELIZA) que da respuestas gen칠ricas, intenta ser gracioso o te pide disculpas por que no te ha entendido.
5. **Responder en s칤 es muy complicado**, pongamos que el usuario te pregunta si est치 lloviendo en Paris. Paris es enorme, tu API del tiempo de pide un c칩digo postal o unas coordenadas, tienes que ser capaz de decidir cu치les darles, con una base de datos o otro servicio que te de coordenadas dada una ciudad... y Paris es f치cil, pero 쯫 si te dicen "C칩rdoba"? 쯃a de Espa침a? 쯃a de Argent칤na? 쯃a de USA? 쮻esde d칩nde pregunta el usuario? tal vez eso pueda servir para saber lo que est치 pidiendo... 쯏 si te pide un dato gen칠rico c칩mo la temperatura m치xima registrada en el Sahara, o una conversi칩n de unidades, o que le des un resumen de un libro o una persona?... es un agujero de conejo que nunca termina. Damos por supuesto un mot칩n de funcionalidad que Google lleva 25 a침os construyendo con cientos de ingenieros y expertos y miles de millones de webs a las que enlazar.

A los pocos meses lleg칩 **GPT2** [el famoso paper de los unicornios](/public/papers/gpt2.pdf) y nos vol칩 la cabeza, intentamos a침adir algo con BERT que diera respuestas libres, se empez칩 a hablar del prompt engineering... Y entonces lleg칩 la mudanza, mi cambio de trabajo, la pandemia... y desconect칠 durante 2 a침os de todo ese mundo bastante de golpe. En alg칰n momento, ~~creo que poco antes de irme de ese trabajo~~ poco despu칠s de irme de ese trabajo, lleg칩 GPT3, yo ya estaba bastante desconectado del tema y tratando de estar a la altura del nuevo trabajo, pero aun as칤 estuve coment치ndolo con mis antiguos compa침eros, porque me pareci칩 impresionante, pero aun as칤 todo el tema del prompt engineering y c칩mo probar GPT3 me pareci칩 demasiado poco determinista, yo estaba liado con otras cosas, as칤 que no le dediqu칠 mucho tiempo y acab칠 olvid치ndome de eso.

Nunca hab칤a sido capaz de estudiar ML y no entend칤a c칩mo se entrenaban los modelos o c칩mo funcionaban. Adem치s el proceso de entrenamiento siempre me ha parecido algo terriblemente aburrido y demasiado azaroso: tienes que esperar d칤as para ver el resultado y lo m치s seguro es que lo tires a la basura, cambias algunos par치metros o revisas los datos de entrenamiento y vuelta a empezar... El ciclo del feedback es demasiado lento. Me gustaba trabajar con TDD en JavaScript, as칤 que abandon칠 todo ese mundo pensando que aun no estaba maduro y no merec칤a la pena para mi.

Imagina mi sorpresa cuando OpenAI anunci칩 ChatGPT y empec칠 a ver de lo que era capaz. 游뱚

[^1]: Estamos hablando de 2017-19, no exist칤a huggingface o estaba muy verde, al igual que la web de Spacy y de encontrar algo en StackOverflow o en blogs especializados ni hablar, hab칤a mucha gente intentando hacer un chatbot, pero la mayor칤a eran cosas muy burdas de 치rboles de decisiones, y pulsa 1 para X, dos para Y, o como mucho algunas regexes a침adidas a esos condicionales...
