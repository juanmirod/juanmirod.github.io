---
published: true
title: Mi experiencia en NLP
layout: post
tags: [opini칩n, Inteligencia Artificial, NLP] 
---

Hace tiempo que quiero contar esta historia bien contada y creo que es ahora o nunca. Mi experiencia personal con el NLP tiene varios a침os y creo que explica por qu칠 me ha interesado tanto ChatGPT y por qu칠 creo que esta tecnolog칤a tiene tanto potencial. Pero empecemos por el principio:

> Warning! tengo muy mala memoria, cualquier parecido con la realidad ser치 casi accidental, voy a tratar de resumir varios a침os de trabajo a grosomodo en un post por dejar constancia de mi viaje y por ordenar un poco mis pensamientos, pero como todo este blog, es p칰blico por si a alguien m치s le puede servir.

Alrededor de 2017 empec칠 a trabajar en una empresa en un proyecto de NLP casi por casualidad. Yo hab칤a trabajado hasta ese momento fundamentalmente con la web, haciendo aplicaciones, juegos, peque침as webs corporativas, campa침as de publicidad... nada demasiado sofisticado y eso si casi siempre trabajando como 칰nico desarrollador, lo que llaman ahora un "full stack": yo hac칤a el backend, la base de datos, las migraciones, la administraci칩n de sistemas y el frontend. S칩lo me faltaba hacer los dise침os. A esta empresa y su forma de trabajar le encaj칩 bastante, porque aunque hab칤a varios desarrolladores, cada uno trabaj치bamos de forma independiente en nuestro proyecto, en nuestra oficina personal. En este caso la infra no hab칤a que gestionarla (oh yeah) pero todo lo dem치s s칤. Incluso, en mi caso, la planificaci칩n del proyecto y la gran mayor칤a de las decisiones ca칤an de mi parte. Digamos que era una especie de investigaci칩n y desarrollo muy aplicado, sin ser yo investigador y sin publicar nada, pero s칤 que un royo bastante libre de "tienes que hacer esto y t칰 te apa침as el c칩mo lo consigues"

La tarea por aquel entonces ya empezaba a estar de moda pero aun todo lo que hab칤a era muy tosco: programar un asistente virtual. Google ten칤a Home, Amazon Alexa, iPhone a Siri, no es que fueran super 칰tiles, pero ah칤 estaban. Y muchas empresas se embarcaron en la tarea de tener su propio chatbot, aunque no ten칤an muy claro c칩mo se hac칤a eso.

En mi caso, al tener mucha libertad y tiempo para desarrollar (no hab칤a pr치cticamente reuniones ni necesidad de coordinaci칩n) me empec칠 a meter en el mundo NLP y en c칩mo programar un Chatbot.

Empec칠 por atacarlo por donde sab칤a. En aquel entonces ya se empezaba a hablar de los modelos de lenguaje, pero yo no ten칤a ni idea de ML ni recursos para aprender o contratar a nadie, as칤 que por el momento descart칠 ese camino y fui investigando sobre lenguajes, sistemas expertos, NLP cl치sico...

As칤 llegu칠 a ChatScript, que es un lenguaje a medida dise침ado y creado por Bruce Wilcox, para programar chatbots. La verdad es que me pareci칩 lo mejor que hab칤a en la 칠poca. En ese momento la mayor칤a de la gente usaba o bien AIML un lenguaje anterior parecido pero basado en XML que era un horror (pero con el que estaba programado el chatbot m치s famoso y exitoso hasta el momento y que sigue en activo: [Mitsuku](https://en.wikipedia.org/wiki/Kuki_AI)), chatscript, con el que Bruce Wilcox hab칤a ganado varias veces el premio Loebner, o python+NLTLK+spacy, que en el momento permit칤a tokenizar el texto de entrada y luego crear un mont칩n de reglas por palabras, por frases, por entity detection etc, que al final se parec칤an bastante a ChatScript, pero eran bastante m치s feas de escribir y de entender y probar. As칤 que me decid칤 por ChatScript.

Encima de ChatScript pude hacer bastantes cositas, llegu칠 a hacer un interface gr치fico que permit칤a crear chatbots sin que el usuario tuviera ni idea de programar, que luego compilaba a ChatScript, generalizando los ejemplos del usuario y que permit칤a probar y debugar tus conversaciones. Me lo pas칠 bomba. Pero si has programado alg칰n sistema parecido ya sabr치s c칩mo acaba la cosa.

Yo hab칤a estado leyendo mucho, sobre Watson, sobre Yedalog, Datalog, sobre modelos de lenguaje, ML, NLP... Hab칤a le칤do un poco a Norvig... De leer todo esto hab칤a sacado muchas ideas y hab칤a a침adido muchas heur칤sticas a mi chatbot, hab칤a a침adido cientos de tests autom치ticos para saber que al a침adir nueva funcionalidad el chatbot no dejaba de responder bien a las acciones que ya conoc칤a... A침ad칤 un peque침o motor l칩gico que permit칤a "ense침arle cosas", es decir guardar hechos y relaciones mediante lenguaje m치s o menos natural... Todo con la intenci칩n de construir un sistema lo bastante flexible como para poder seguir a침adi칠ndole "servicios" o piezas que lo hicieran m치s inteligente, como en Watson. Desde el principio el chatbot pod칤a recibir de input y responder en cualquier idioma gracias a la API de traducci칩n de Google, que hac칤a la conversi칩n y de algunas reglas para detectar, almacenar el idioma y hacer la conversi칩n de la salida desde ese momento para ese usuario.

Yo estaba bastante contento con mi peque침o sistema experto multirepo que era capaz de responder a un pu침ado de preguntas, hacer bromas y tener peque침as conversaciones, siempre que preguntaras la pregunta adecuada...

Tratar de programar un chatbot o un asistente gen칠rico, que responda airosamente a texto libre, escribiendo reglas a mano, es una tarea imposible. Por mucho que generalicen tus reglas, mucho entity detection, bases de datos con ciudades, nombres, animales y dem치s que tengas, por m치s que tokenices la frase y que elimines las palabras supl칠rfluas como los art칤culos, por m치s que uses regex en tus reglas, siempre llegar치 el usuario, intentar치 hablar con tu programa y tu programa fracasar치 estrepitosamente en entenderlo si no a la primera, a la segunda frase.

Pero entonces en la empresa me hicieron un regalo: Un compa침ero!! Hab칤a otro programador, esta vez alguien especializado en ML, que estaba intentando el mismo problema usando todo ese royo de Python y Spacy, con el mismo o menos 칠xito que yo, as칤 que nos pusimos los dos a intentar aunar fuerzas.

Yo ya ten칤a el servidor funcionando y adem치s como hab칤a a침adido todos esos m칩dulos independientes y hab칤a ido desacoplando todo, pod칤a incorporar otro servidor, en este caso de ML que respondiera a todo aquello que a mi chatbot se le escapaba. Al principio fue solo eso, luego fuimos a침adiendo pesos, y si el ML estaba muy seguro de la respuesta, respond칤a el ML, si no, el chatbot, si el chatbot no ten칤a respuesta, respond칤amos algo gen칠rico.

Para poder encajar todo esto, ayud칠 un poco con el servidor de Python del sistema de ML, y esto me permiti칩 acercarme un poco m치s a ese mundo. En el lado de Python usamos flask para el servidor y RASA para el chatbot. RASA ten칤a apenas unos meses y estaba muy verde, us치bamos spacy para tokenizaci칩n y otras tareas cl치sicas de NLP pero por debajo de RASA lo customizamos un poco y el otro programador ten칤a tus propios modelos para detecci칩n de entidades y generaci칩n de lenguaje.

Todo esto fue antes de GPT2, y trat치bamos de seguir los 칰ltimos papers que iban saliendo sobre el tema. Yo me hab칤a familiarizado con los papers acad칠micos porque sobre todo este tema apenas encontrabas informaci칩n y cursos m치s asequibles en la web, y aunque pasaba de largo de las matem치ticas, pod칤a leer m치s o menos los papers que 칤bamos viendo que pod칤an ser interesantes.

Ni que decir tiene que nuestro chatbot sequ칤a siendo bastante patata, pero tenia un mont칩n de funcionalidades si sab칤as usarlo. Este era el problema todo el rato antes de GPT3.5, simplemente no exist칤a nada que entendiera la pregunta y diera una respuesta coherente. Ahora mismo nos quejamos de que la IA se inventa cosas, pero el salto es abismal, en 2019 el estado del arte era:

1. Tokenizar y limpiar la entrada
2. Detecci칩n de entidades con diccionarios en el lado cl치sico o con un NER en ML.
3. Clasificaci칩n de la intenci칩n de la frase: 
    - En el lado cl치sico esto eran cientos o miles de reglas y regex para tratar de hacer matchear la frase con un patr칩n conocido.
    - En ML pod칤as entrenar un clasificador con las intenciones que tuvieras y el clsaificador te daba una intenci칩n o varias con un margen de confianza.
4. Con la intenci칩n, si tienes algo con confianza alta, y tienes las entidades (variables como Paris, Juan o concierto) puedes intentar responder. Si no, tienes un backup tipo ELISA que da respuestas gen칠ricas, intenta ser gracioso o te pide disculpas por que no te ha entendido. 
5. Responder en s칤 es muy complicado, pongamos que el usuario te pregunta si est치 lloviendo en Paris. Paris es enorme, tu API del tiempo de pide un c칩digo postal o unas coordenadas, tienes que ser capaz de decidir cu치les darles, con una base de datos o otro servicio que te de coordenadas dada una ciudad... y Paris es f치cil, pero 쯫 si te dicen "C칩rdoba"? 쯃a de Espa침a? 쯃a de Argent칤na? 쯃a de USA? 쮻esde d칩nde pregunta el usuario? tal vez eso pueda servir para saber lo que est치 pidiendo... 쯏 si te pide un dato gen칠rico c칩mo la temperatura m치xima registrada en el Sahara, o una conversi칩n de unidades, o que le des un resumen de un libro o una persona?... es un agujero de conejo que nunca termina. Damos por supuesto un mot칩n de funcionalidad que Google lleva 25 a침os construyendo con cientos de ingenieros y expertos y miles de millones de webs a las que enlazar.

A los pocos meses lleg칩 GPT2 y nos vol칩 la cabeza, intentamos a침adir algo con bERT que diera respuestas libres, se empez칩 a hablar del prompt engineering... En alg칰n momento, creo que poco antes de irme de ese trabajo lleg칩 GPT3. Y entonces lleg칩 la mudanza, mi cambio de trabajo, la pandemia... y desconect칠 durante 2 a침os de todo ese mundo bastante de golpe. 

Nunca hab칤a sido capaz de estudiar ML y no entend칤a c칩mo se entrenaban los modelos o c칩mo funcionaban. Adem치s el proceso de entrenamiento siempre me ha parecido algo terriblemente aburrido, tienes que esperar d칤as para ver el resultado y lo m치s seguro es que lo tires a la basura. El ciclo del feedback es demasiado lento. Me gustaba trabajar con TDD en JavaScript, as칤 que abandon칠 todo ese mundo pensando que aun no estaba maduro y no merec칤a la pena.

Imagina mi sorpresa cuando OpenAI anunci칩 ChatGPT y empec칠 a ver de lo que era capaz. 游뱚 (Continuar치...)